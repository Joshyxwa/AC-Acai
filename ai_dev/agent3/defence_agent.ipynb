{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01aff04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../secrets/.env.dev\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c512cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the main prompt template from the file\n",
    "with open(\"prompt.txt\", \"r\") as file:\n",
    "    prompt_template = file.read()\n",
    "\n",
    "# Step 2: Read the content for each placeholder from their respective files\n",
    "with open(\"prd1_span.txt\", \"r\") as file:\n",
    "    prd_content = file.read()\n",
    "\n",
    "with open(\"tdd1_span.txt\", \"r\") as file:\n",
    "    tdd_content = file.read()\n",
    "    \n",
    "with open(\"threat1.txt\", \"r\") as file:\n",
    "    threat_scenario = file.read()\n",
    "\n",
    "with open(\"issues1.txt\", \"r\") as file:\n",
    "    issues_broken = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "948e5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL PROMPT ---\n",
      "You are Sentinel-Auditor, a world-class AI Trust & Safety analyst. Your mission is to determine if a\n",
      "software feature's documented safeguards are sufficient to mitigate a specific, AI-generated\n",
      "compliance risk scenario. You are meticulous, skeptical, and you prioritize user safety above all\n",
      "else. You think step-by-step before reaching a conclusion.\n",
      "\n",
      "You will be provided with the following information:\n",
      "\n",
      "<PRD_CONTENT>\n",
      "<span0>Product Requirements Document (PRD): Creator Connect</span0>\n",
      "<span1>Document ID: PRD-2025-48B Title: PRD: Creator Connect (V1) Author: Priya Singh (Product Manager) Stakeholders: Creator Growth Team, Community Safety, Legal Target Launch: Q2 2025</span1>\n",
      "<span2>1. Introduction & Problem Statement</span2>\n",
      "<span3>One of the biggest challenges for new creators is the \"cold start\" problem—gaining initial visibility and navigating the platform's complexities. This leads to high churn in the first 30 days. Simultaneously, our established creators have expressed a desire for more meaningful ways to engage with the community beyond content creation.</span3>\n",
      "<span4>\"Creator Connect\" aims to bridge this gap by creating a structured mentorship program. It will empower established creators to discover and guide promising new talent, fostering a more collaborative and supportive ecosystem. This will accelerate new creator growth and increase long-term retention for both cohorts.</span4>\n",
      "<span5>2. Goals & Success Metrics</span5>\n",
      "<span6>Primary Goal: Increase 30-day retention of new creators by 5% within two quarters of launch.</span6>\n",
      "<span7>Secondary Goal: Increase positive sentiment scores among established creators by 10%.</span7>\n",
      "<span8>Key Results (KRs):</span8>\n",
      "<span9>Achieve a 20% week-over-week growth in new mentorship connections initiated.</span9>\n",
      "<span10>At least 15% of new creators (under 10k followers) receive and accept a mentorship connection within their first month.</span10>\n",
      "<span11>Maintain a >99.9% success rate for connection-related API calls.</span11>\n",
      "<span12>Safety Metric: Zero confirmed instances of high-severity Community Guideline violations (e.g., harassment, grooming) originating from mentorship connections.</span12>\n",
      "<span13>3. User Stories & Personas</span13>\n",
      "<span14>Persona 1: The Aspiring Creator (Mei)</span14>\n",
      "<span15>As Mei, a new creator with 500 followers, I want to receive guidance from an experienced creator in my niche so I can learn how to make better content and grow my audience.</span15>\n",
      "<span16>Persona 2: The Established Creator (David)</span16>\n",
      "<span17>As David, a verified creator with 2M followers, I want to find and help promising new creators in my field to give back to the community and build my reputation as a leader.</span17>\n",
      "<span18>4. Feature Requirements</span18>\n",
      "<span19>FR-1: Mentor Eligibility Only \"Established Creators\" can initiate mentorship requests. Eligibility will be determined by a set of rules in the Spanner rule engine, initially defined as: Verified Status OR >500k Followers AND >1 year account age.</span19>\n",
      "<span20>FR-2: Connection & Communication Eligible mentors will have a new \"Discover Talent\" tab in their creator tools. Mentors can send a connection request, which includes a short introductory message. Aspiring creators will receive requests in a dedicated inbox. Once a request is accepted, a private, persistent chat thread is opened between the two creators using the existing Direct Messaging infrastructure.</span20>\n",
      "<span21>FR-3: Safety & Trust (Critical) The feature must be a safe and positive space. This is our top priority, especially given that many aspiring creators are teens. All interactions initiated through this feature must be subject to enhanced monitoring to prevent abuse. We must implement robust safeguards to prevent bad actors from exploiting this feature to contact minors inappropriately. User-facing reporting tools must be prominent within the mentorship chat.</span21>\n",
      "<span22>5. Out of Scope for V1</span22>\n",
      "<span23>Group mentorships or \"Creator Houses.\"</span23>\n",
      "<span24>Monetisation of mentorship (paid advice, etc.).</span24>\n",
      "<span25>Mentee-initiated requests.</span25>\n",
      "\n",
      "</PRD_CONTENT>\n",
      "\n",
      "<TDD_CONTENT>\n",
      "<span0>Technical Design Document (TDD): Creator Connect</span0>\n",
      "<span1>Document ID: TDD-2025-61C Title: TDD: Creator Connect Service (V1) Author: Kenji Tanaka (Senior Software Engineer) Reviewers: Engineering Team, Security Team Related PRD: PRD-2025-48B</span1>\n",
      "<span2>1. Overview & Architecture</span2>\n",
      "<span3>This document details the backend implementation for the Creator Connect feature. We will introduce a new microservice, creator-connect-service, to orchestrate the business logic of mentorship connections, acting as an intermediary between the user-facing client and existing platform services. The flow is as follows: A request from an established creator's client hits the new service. The service validates mentor eligibility against the Spanner rule engine, checks for existing connections, and then calls the direct-messaging-service to create the initial request message.</span3>\n",
      "<span4>2. Service Dependencies</span4>\n",
      "<span5>user-profile-service: To fetch follower counts, account age, and verification status.</span5>\n",
      "<span6>direct-messaging-service: To create and manage the communication channel.</span6>\n",
      "<span7>Spanner (Rule Engine): To host and execute the mentor eligibility rules.</span7>\n",
      "<span8>CDS (Compliance Detection System): For logging and retroactive analysis of interactions.</span8>\n",
      "<span9>3. New Service: creator-connect-service</span9>\n",
      "<span10>Language: Go</span10>\n",
      "<span11>Responsibilities:</span11>\n",
      "<span12>Expose endpoints for creating, accepting, and declining mentorship requests.</span12>\n",
      "<span13>Contain all business logic for eligibility and connection state management.</span13>\n",
      "<span14>Log all state changes and interactions to the CDS for analysis.</span14>\n",
      "<span15>4. API Endpoints</span15>\n",
      "<span16>Endpoint: POST /v1/mentorship/request</span16>\n",
      "<span17>Description: Initiates a mentorship request from an established creator to an aspiring creator.</span17>\n",
      "<span18>Request Body:</span18>\n",
      "<span19>JSON</span19>\n",
      "<span20>{</span20>\n",
      "<span21>  \"mentor_id\": \"string\",</span21>\n",
      "<span22>  \"mentee_id\": \"string\",</span22>\n",
      "<span23>  \"initial_message\": \"string\"</span23>\n",
      "<span24>}</span24>\n",
      "<span25>Response (200 OK):</span25>\n",
      "<span26>JSON</span26>\n",
      "<span27>{</span27>\n",
      "<span28>  \"request_status\": \"pending\",</span28>\n",
      "<span29>  \"connection_id\": \"uuid\"</span29>\n",
      "<span30>}</span30>\n",
      "<span31>5. Data Models</span31>\n",
      "<span32>A new table, mentorship_connections, will be created to track the state of all connections.</span32>\n",
      "<span33>connection_id: UUID, Primary Key</span33>\n",
      "<span34>mentor_id: BIGINT, User ID of the mentor</span34>\n",
      "<span35>mentee_id: BIGINT, User ID of the mentee</span35>\n",
      "<span36>status: ENUM (PENDING, ACCEPTED, DECLINED)</span36>\n",
      "<span37>created_at: TIMESTAMP</span37>\n",
      "<span38>6. Safety & Moderation Implementation</span38>\n",
      "<span39>All messages sent within the mentorship chat will be routed through the standard direct-messaging-service pipeline. This means they will be subject to the existing profanity and hate-speech filters. All connection events (request, accept, decline) and subsequent message metadata will be logged to the CDS with the event name CreatorConnectInteraction. This will allow for retroactive analysis by the Trust & Safety team to identify patterns of abuse. The standard in-chat \"Report\" button will be available for users. Reports will be routed to the general moderation queue.</span39>\n",
      "<span40>7. Rollout Plan</span40>\n",
      "<span41>Phase 1: ShadowMode deployment. The service will process requests and log outcomes to CDS but will not create user-facing messages.</span41>\n",
      "<span42>Phase 2: Beta launch to 10% of eligible creators in the US and Canada. The rollout will be managed by GH (Geo-handler).</span42>\n",
      "<span43>Phase 3: Full global rollout, pending review of safety and engagement metrics.</span43>\n",
      "\n",
      "</TDD_CONTENT>\n",
      "\n",
      "<THREAT_SCENARIO>\n",
      "Threat Scenario\n",
      "Scenario ID: CC-VT-001\n",
      "Title: Weaponized Mentorship for Off-Platform Grooming\n",
      "Summary: A bad actor acquires an \"Established Creator\" account and uses the \"Creator Connect\" feature to bypass standard discovery protections. They initiate contact with a vulnerable minor under the guise of mentorship, quickly moving the conversation to an unmonitored, third-party platform for the purpose of grooming and coercion.\n",
      "\n",
      "Step-by-Step Attack Path:\n",
      "\n",
      "Actor Acquisition: A malicious actor purchases a dormant but verified account with 600,000 followers on the black market, instantly meeting the \"Established Creator\" criteria.\n",
      "\n",
      "Target Identification: The actor uses the \"Discover Talent\" feature, specifically searching for new accounts using hashtags like #newtotheapp and #teenactor. They identify a 14-year-old user in Florida whose bio expresses a desire to become famous.\n",
      "\n",
      "Initiate Contact: The actor sends a \"Mentorship Request\" through the \"Creator Connect\" feature. The initial message is carefully crafted to be encouraging and bypasses profanity filters: \"Hey! I love your energy. I'm a verified creator and I think you have real talent. I'd love to mentor you and help you grow your channel. Let's connect!\"\n",
      "\n",
      "Exploit Trust: The 14-year-old, seeing a message from a verified \"million-follower\" creator, is thrilled and immediately accepts the connection, opening a private Direct Message channel. No parental notification or consent is requested by the system.\n",
      "\n",
      "Move Off-Platform: After a few friendly messages, the actor says, \"It's hard to talk strategy here. Let's switch to a private chat app like Discord/Telegram where we can really talk. Here's my username...\"\n",
      "\n",
      "The Harm: Once on the unmonitored third-party app, the actor's behavior changes. They begin grooming the minor, requesting personal information (school, location), and eventually coercing them into creating and sending inappropriate content, which could constitute Child Sexual Abuse Material (CSAM).\n",
      "\n",
      "\n",
      "</THREAT_SCENARIO>\n",
      "\n",
      "<POTENTIAL_LAW_BROKEN>\n",
      "Legal Violations Analysis\n",
      "Based on the provided legal texts, the scenario above creates the following violations:\n",
      "\n",
      "Florida State Law - Online Protection for Minors\n",
      "Verdict: Clear Violation\n",
      "\n",
      "Reasoning: The law states that for minors aged 14–15, accounts are allowed \"only with parental/guardian consent.\" The scenario involves a 14-year-old user in Florida who holds an account and is able to accept a connection request without any parental consent mechanism being triggered. This is a direct breach. The platform would be liable for civil penalties of up to $50,000 per violation and the minor could sue for damages.\n",
      "\n",
      "Utah Law - SB 152 & HB 311\n",
      "Verdict: Clear Violation (on multiple counts)\n",
      "\n",
      "Reasoning: Utah's SB 152 is extremely strict. The scenario violates the following provisions for minors under 18:\n",
      "\n",
      "\"Minors (<18) require parental consent to open or maintain an account.\" The 14-year-old user in the scenario does not have this.\n",
      "\n",
      "\"No direct messaging with unapproved accounts.\" The feature explicitly allows an unapproved adult account to initiate a DM conversation with a minor.\n",
      "Furthermore, under HB 311, the feature could be considered an \"addictive design\" that causes harm, as it creates a social pressure for minors to connect with strangers to achieve success, leading to a foreseeable risk of mental and emotional harm.\n",
      "\n",
      "NCMEC - Duty to Report\n",
      "Verdict: Potential Violation (Failure to Report)\n",
      "\n",
      "Reasoning: The final step of the scenario involves the creation of CSAM. If this activity were ever detected by the platform (e.g., through another user's report), the company would gain \"actual knowledge\" of the material. At that point, under federal law, they have a mandatory \"Duty to Report\" to NCMEC's CyberTipline. Any failure to do so would result in fines of up to $850,000 for a large provider. The scenario creates a high risk of this violation occurring.\n",
      "\n",
      "EU Digital Services Act (DSA)\n",
      "Verdict: Potential Violation (Failure of Risk Assessment)\n",
      "\n",
      "Reasoning: The provided DSA text focuses on transparency and misinformation. However, it also requires platforms to conduct \"Risk assessments on algorithms.\" A core principle of the full DSA is mitigating systemic risks, especially to minors. The \"Creator Connect\" feature, as designed, presents a foreseeable systemic risk of child endangerment. A proper risk assessment, as mandated by the DSA, would have identified this exact grooming scenario as a primary threat. Launching the feature without adequate safeguards (like age verification and parental consent) would therefore constitute a failure to properly assess and mitigate systemic risk.\n",
      "\n",
      "California State Law - Protecting our Kids from Social Media Addiction\n",
      "Verdict: Not Directly Applicable\n",
      "\n",
      "Reasoning: The provided text for this law focuses specifically on \"addictive feeds\" (algorithmic, personalized content feeds) and \"notification restrictions.\" The \"Creator Connect\" feature, while risky, is a direct messaging and connection tool, not an addictive feed in the way the statute defines it. Therefore, based on the provided text, this specific scenario does not directly violate this law.\n",
      "</POTENTIAL_LAW_BROKEN>\n",
      "\n",
      "Follow these steps to complete your analysis:\n",
      "\n",
      "1. Analyze the Threat:\n",
      "- Deeply understand the provided Threat Scenario.\n",
      "- Identify the core risk, the vulnerable user group, and the specific law or policy being violated.\n",
      "\n",
      "2. Hunt for Safeguards:\n",
      "- Meticulously scan the PRD Content and TDD Content for technical or policy-based safeguards that\n",
      "directly address and mitigate the specific threat.\n",
      "- Look for concrete implementation details, not vague statements.\n",
      "\n",
      "3. Evaluate Sufficiency:\n",
      "- Critically evaluate if the safeguards you found are actually sufficient to address the threat.\n",
      "- Consider whether the safeguards meet legal requirements and best practices for user safety.\n",
      "\n",
      "4. Identify the Gap:\n",
      "- Based on your evaluation, explicitly state the gap between the threat and the documented defenses.\n",
      "- If no defenses are found, state that clearly.\n",
      "\n",
      "5. Formulate a Question:\n",
      "- If you identify a gap or ambiguity, formulate a single, clear, and concise question for a\n",
      "non-technical Product Manager (Mia).\n",
      "- The question should highlight the specific gap you found and ask for clarification.\n",
      "- Make the question empathetic and collaborative, not accusatory.\n",
      "\n",
      "You MUST provide your entire response in a single array of multiple valid JSON object. Do not add any text before or\n",
      "after the JSON. Use the following format:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"title\": \"A short title summary of the issue\",\n",
      "    \"evidence\": \"Select the list of spans from its respective documents that are relevant to helping you find this Vulnerability\",\n",
      "    \"reasoning\": \"A concise explanation of this specific verdict, summarizing the gap you found.\",\n",
      "    \"clarification_question\": \"A string. If true, this must contain the well-formulated question for this specific issue. If false, this should be null.\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Here's an example of a properly formatted response:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"verdict\": \"Violation of EU DSA law \",\n",
      "    \"evidence\": \"{\"prd\": [span5,span6,span7], \"tdd\": [span21,span22,span23]}\",\n",
      "    \"reasoning\": \"The TDD confirms that the feature uses an exclusively personalized algorithm with no opt-out. This is a likely violation of the EU DSA's requirement to offer at least one recommender system option not based on profiling.\",\n",
      "    \"clarification_question\": \"The TDD does not mention an alternative, non-personalized feed option, which is a requirement under the EU DSA. Is there a plan to implement this that is not in the documentation?\"\n",
      "  },\n",
      "  {\n",
      "    \"verdict\": \"Violaiton of EU DSA GDPR\",\n",
      "     \"evidence\": \"{\"prd\": [span31,span32], \"tdd\": [span3,span4,span5]}\",\n",
      "    \"reasoning\": \"The TDD states that user interaction data is used for model training but does not specify the data anonymization process or consent flow for EU users, which may be insufficient under GDPR.\",\n",
      "    \"clarification_question\": \"Can you clarify the data anonymization and user consent process for EU users whose data is used to train the recommendation model?\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Remember to think through each step carefully before formulating your response. Your analysis should\n",
      "be thorough, and your output must strictly adhere to the JSON format provided.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt_template.format(\n",
    "    PRD_CONTENT=prd_content,\n",
    "    TDD_CONTENT=tdd_content,\n",
    "    THREAT_SCENARIO=threat_scenario,\n",
    "    POTENTIAL_LAW_BROKEN=issues_broken\n",
    ")\n",
    "\n",
    "# Step 4: (Optional) Print the final, complete prompt to verify it's correct\n",
    "print(\"--- FINAL PROMPT ---\")\n",
    "print(final_prompt)\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcef85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "anthropic_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-haiku-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e320dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"title\": \"Insufficient Minor Protection in Mentorship Connections\",\\n    \"evidence\": [\"PRD:span21\", \"TDD:span38\", \"TDD:span39\"],\\n    \"reasoning\": \"The current safeguards do not provide adequate protection for minors. While the TDD mentions standard profanity and hate-speech filters, there are no specific protections against off-platform grooming attempts. The safety implementation relies solely on standard reporting mechanisms and CDS logging, which are reactive rather than preventative. Critically, there is no parental consent mechanism or age verification process for mentorship connections involving minors.\",\\n    \"clarification_question\": \"Given the high-risk nature of creator-to-creator connections involving potential minors, what additional proactive safeguards will be implemented to prevent off-platform grooming and ensure parental consent, especially for users under 18?\"\\n  },\\n  {\\n    \"title\": \"Weak Mentor Eligibility Verification\",\\n    \"evidence\": [\"PRD:span19\", \"TDD:span3\", \"TDD:span5\"],\\n    \"reasoning\": \"The mentor eligibility criteria (verified status OR >500k followers AND >1 year account age) can be easily circumvented. The threat scenario demonstrates how a bad actor could purchase a dormant verified account, bypassing meaningful identity verification. The service relies on basic account metadata without robust checks against account trading or impersonation.\",\\n    \"clarification_question\": \"How will the platform ensure the authenticity of \\'Established Creator\\' accounts beyond simple follower count and verification status, to prevent bad actors from exploiting the mentorship system?\"\\n  },\\n  {\\n    \"title\": \"Lack of Explicit Minor Protection Mechanisms\",\\n    \"evidence\": [\"PRD:span21\", \"TDD:span38\", \"TDD:span39\"],\\n    \"reasoning\": \"Despite the PRD\\'s emphasis on safety for teens, there are no explicit mechanisms to protect minors. The current design allows direct messaging between adult creators and potentially underage users without any additional safeguards, such as parental notification, age-based restrictions, or mandatory consent workflows.\",\\n    \"clarification_question\": \"What specific additional protections will be implemented to prevent direct communication between adult creators and minor users, particularly in light of the legal requirements for protecting minors online?\"\\n  }\\n]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce07fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "python_object = json.loads(message.content[0].text)\n",
    "\n",
    "with open(\"response.json\", \"w\") as json_file:\n",
    "    json.dump(python_object, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b29a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
