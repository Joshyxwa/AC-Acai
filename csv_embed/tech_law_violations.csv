
law,company,full_text,link
FTC Act and 2012 privacy order,Facebook (Meta Platforms),"Facebook deceived users about their ability to control the privacy of their personal information and engaged in “unfair and deceptive” practices that violated a 2012 FTC privacy order.  The 2019 FTC press release states that Facebook improperly shared user data, including the Cambridge Analytica scandal, and misrepresented the extent of its controls.  The settlement required Facebook to pay a record-breaking $5 billion penalty and imposed new restrictions, including creating an independent privacy committee, appointing compliance officers, requiring independent third-party assessments, and limiting its use of phone numbers for advertising.  The order also imposed strict data‑security and privacy requirements for at least 20 years and mandated quarterly certifications that the company is in compliancehttps://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook#:~:text=FTC%20Imposes%20%245%20Billion%20Penalty,New%20Privacy%20Restrictions%20on%20Facebookhttps://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook#:~:text=independent%20assessor%2C%20as%20well%20as,company%E2%80%99s%20discovery%20of%20the%20incident.",https://www.ftc.gov/news-events/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook
FTC Act and 2011 order,Twitter,"The FTC charged Twitter with violating a 2011 privacy order and the FTC Act by deceptively using phone numbers and email addresses collected for account security to target advertising.  According to the 2022 FTC press release, Twitter asked users to provide phone numbers or email addresses for multi-factor authentication but then used that information to sell targeted ads.  Twitter had promised users it would not use the information for advertising but broke that promise.  The company agreed to pay a $150 million penalty and implement a comprehensive privacy and information security program, including regular assessments and reporting to the FTChttps://www.ftc.gov/news-events/news/press-releases/2022/05/ftc-charges-twitter-deceptively-using-account-security-data-sell-targeted-ads#:~:text=FTC%20Charges%20Twitter%20with%20Deceptively,Data%20to%20Sell%20Targeted%20Ads.",https://www.ftc.gov/news-events/news/press-releases/2022/05/ftc-justice-department-order-twitter-pay-150-million-violating-2011-ftc-order-misrepresenting
Children’s Online Privacy Protection Act (COPPA),Google/YouTube,"The FTC and New York Attorney General filed a complaint against Google and its YouTube subsidiary alleging that the companies illegally collected personal information from children without notifying parents or obtaining consent as required by COPPA.  According to the FTC’s 2019 press release, YouTube illegally gathered data using persistent identifiers on child-directed channels and used it to deliver targeted ads.  The settlement imposed a record $170 million penalty – $136 million to the FTC and $34 million to New York – and required YouTube to develop a system for channel owners to flag child-directed content, notify parents and obtain verifiable consent before collecting data, and implement COPPA compliance traininghttps://www.ftc.gov/news-events/news/press-releases/2019/09/google-youtube-will-pay-record-170-million-alleged-violations-childrens-privacy-law#:~:text=Google%20and%20YouTube%20Will%20Pay,Violations%20of%20Children%E2%80%99s%20Privacy%20Law.",https://www.ftc.gov/news-events/press-releases/2019/09/google-youtube-pay-record-170-million-penalty-alleged-violations-coppa
Children’s Online Privacy Protection Act (COPPA),TikTok/Musical.ly,"In 2019 the FTC reached a settlement with the operators of the video‑sharing app Musical.ly (now TikTok) for violating COPPA by collecting personal information from children under 13 without parental consent.  The complaint alleged that the app allowed children to create accounts and post videos publicly without adequate notice or parental verification.  It also failed to honor requests to delete children’s personal information.  The FTC’s blog post noted that Musical.ly defaulted accounts to public, permitted adults to contact minors through direct messages, and allowed the collection of names, email addresses and other details.  The settlement required the company to pay $5.7 million, the largest civil penalty under COPPA at that time, delete data collected from children, and comply with COPPA going forwardhttps://www.ftc.gov/business-guidance/blog/2019/02/largest-ftc-coppa-settlement-requires-musically-change-its-tune#:~:text=Largest%20FTC%20COPPA%20settlement%20requires,ly%20to%20change%20its%20tune.",https://www.ftc.gov/news-events/blogs/business-blog/2019/02/largest-ftc-coppa-settlement-requires-musically-change-its-tune
Section 5 of the FTC Act (deception) and privacy misrepresentations,Cambridge Analytica (and associated parties),"The FTC filed an administrative complaint against Cambridge Analytica, former CEO Alexander Nix, and app developer Aleksandr Kogan for deceiving Facebook users about the collection of personal data.  The complaint alleged they represented that the GSRApp did not collect user names or personal information when in fact it harvested data from tens of millions of Facebook users for voter profiling.  The FTC press release describes that the proposed settlement orders would require Kogan and Nix to delete any data collected and to destroy or delete all models or algorithms derived from it.  They must also provide a certification to the FTC, and any misrepresentations about privacy and confidentiality would constitute future violationshttps://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-sues-cambridge-analytica-settles-former-ceo-app-developer#:~:text=FTC%20Sues%20Cambridge%20Analytica%2C%20Settles,Former%20CEO%20and%20App%20Developer.",https://www.ftc.gov/news-events/press-releases/2019/07/ftc-sends-settlement-agreements-cambridge-analytica-cofounder-kogan-former-ceo-alexander-nix-public
FTC Act – deceptive practices and privacy misrepresentations,Snapchat,"Snapchat settled FTC charges that it deceived consumers by promising that messages would “disappear forever” when in fact recipients could save messages using third‑party applications or by taking screenshots without notification.  The 2014 FTC press release explains that Snapchat also collected user location data and stored video content unencrypted on its servers.  It misrepresented its data collection practices and failed to secure its Find Friends feature, leading to the theft of 4.6 million user names and phone numbers.  Under the settlement, Snapchat agreed not to misrepresent how it maintains the privacy, security or confidentiality of users’ information, implement a comprehensive privacy program, and obtain biennial independent assessments for 20 yearshttps://www.ftc.gov/news-events/news/press-releases/2014/05/snapchat-settles-ftc-charges-promises-disappearing-messages-were-false#:~:text=Snapchat%20Settles%20FTC%20Charges%20That,of%20Disappearing%20Messages%20Were%20False.",https://www.ftc.gov/news-events/press-releases/2014/05/snapchat-settles-ftc-charges-promised-dissapearing-messages-deceived-users
FTC Act – deceptive security claims and unfair practices,Zoom,"The FTC alleged that Zoom misled users by claiming its video‑conferencing platform offered 256‑bit end‑to‑end encryption.  In reality, Zoom kept cryptographic keys that allowed it to access meetings, and it only used 128‑bit encryption.  The complaint also alleged Zoom installed a hidden web server on Apple devices without user consent, which bypassed browser security and persisted even after uninstalling Zoom.  The 2020 FTC press release describes that the proposed settlement prohibited Zoom from misrepresenting its privacy and security practices, required it to implement a comprehensive security program, undergo independent assessments and notify users before making material changes to data practiceshttps://www.ftc.gov/news-events/news/press-releases/2020/11/ftc-requires-zoom-enhance-its-security-practices-part-settlement#:~:text=FTC%20Requires%20Zoom%20to%20Enhance,Practices%20as%20Part%20of%20Settlement.",https://www.ftc.gov/news-events/press-releases/2020/11/ftc-approves-final-settlement-prohibiting-zoom-securely-lying-consumers-about-encryption
COPPA and New York General Business Law – failure to verify users and protect minors’ data,Saturn Technologies (Saturn app),"A March 2025 settlement between New York Attorney General Letitia James and Saturn Technologies resolved allegations that the Saturn scheduling app failed to verify users’ age or school affiliation, allowing adults to access high‑schoolers’ schedules.  The press release explains that the company’s “verify school” feature did not actually verify that users attended the school they selected; instead it allowed sign‑ups from any email address.  Investigators also found that Saturn failed to verify users’ age and allowed children under 13 to sign up without parental consent, in violation of COPPA.  The settlement required Saturn to pay $650,000, implement robust age and school verification, delete contact information collected via phonebook syncing, provide parental consent notices, and restrict public display of minors’ scheduleshttps://ag.ny.gov/press-release/2025/attorney-general-james-announces-settlement-app-developer-failing-protect-young#:~:text=Attorney%20General%20James%20Announces%20Settlement,to%20Protect%20Young%20Users%E2%80%99%20Privacy.",https://ag.ny.gov/press-release/2025/mar/ag-james-announces-settlement-saturn-technologies-protect-privacy-students
Texas Capture or Use of Biometric Identifier (CUBI) Act and Deceptive Trade Practices Act,Meta Platforms (Facebook),"On July 30, 2024, Texas Attorney General Ken Paxton announced a $1.4 billion settlement with Meta for unlawfully capturing Texans’ biometric identifiers without consent.  The press release states that Meta’s ‘Tag Suggestions’ feature used facial recognition technology to collect the facial geometry of millions of Texans and stored it indefinitely.  This violated the Texas CUBI Act, which prohibits collecting biometric data without informed consent, and the Deceptive Trade Practices Act.  The settlement requires Meta to pay the penalty over five years, delete all previously collected biometric data, and obtain informed consent before capturing biometric identifiershttps://www.texasattorneygeneral.gov/news/releases/attorney-general-ken-paxton-secures-14-billion-settlement-meta-over-its-unauthorized-capture#:~:text=July%2030%2C%202024%20,Release.",https://www.texasattorneygeneral.gov/news/releases/ag-paxton-announces-historic-settlement-recovering-14-billion-texas-fight-biometric-privacy
Fair Housing Act (discrimination in housing ads),Meta Platforms (Facebook),"The U.S. Department of Justice filed a complaint in 2022 alleging that Meta’s housing advertising system unlawfully discriminated based on race, color, religion, sex, disability, familial status and national origin.  The complaint claimed Meta allowed advertisers to target housing ads to users based on protected characteristics using its “Special Ad Audience” tool.  On June 27, 2022, the parties reached a settlement requiring Meta to discontinue the tool, develop a “Variance Reduction System” to reduce disparities, pay a civil penalty of $115,054, and subject itself to DOJ monitoring.  The DOJ press release emphasised that the Fair Housing Act prohibits discrimination in housing advertising and that the settlement will ensure equitable accesshttps://www.justice.gov/crt/case/united-states-v-meta-platforms-inc-fka-facebook-inc-sdny.",https://www.justice.gov/opa/pr/justice-department-secures-groundbreaking-agreement-meta-platforms-remedy-acts-discrimination
UK Data Protection Act (GDPR) – failure to protect children’s data,TikTok,"The UK Information Commissioner’s Office fined TikTok £12.7 million in April 2023 for allowing around 1.4 million UK children under 13 to access the platform and for misusing their personal data.  The ICO press release notes that TikTok failed to do enough to verify children’s ages, did not obtain parental consent, and provided inadequate information to users about how their data was collected and used.  UK data protection law requires parental consent before personal data of children under 13 can be used.  The ICO emphasised that TikTok should have removed children from the platform and that its privacy notices were insufficienthttps://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2023/04/ico-fines-tiktok-127-million-for-misusing-children-s-data/#:~:text=The%20Information%20Commissioner%E2%80%99s%20Office%20,use%20children%E2%80%99s%20personal%20data%20lawfully.",https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2023/04/ico-fines-tiktok-12-7m-for-misusing-children-s-data/
GDPR fairness and data protection by design requirements,TikTok,"In September 2023, the European Data Protection Board (EDPB) announced a binding decision finding that TikTok violated the GDPR’s fairness principle when presenting privacy options to children aged 13 to 17.  TikTok designed pop‑up windows that nudged young users to choose public accounts and to post content immediately, while options for private accounts and drafts were harder to access.  The EDPB found these dark patterns unfair and manipulative and instructed the Irish Data Protection Commission to order TikTok to eliminate the practices.  The decision also required TikTok to pay a €345 million fine and ensure its design complies with data protection by design and defaulthttps://www.edpb.europa.eu/news/news/2023/following-edpb-decision-tiktok-ordered-eliminate-unfair-design-practices-concerning_en#:~:text=Brussels%2C%2015%20September%C2%A0%E2%80%93%20Following%20the,July%20and%2031%20December%202020.",https://edpb.europa.eu/news/news/2023/edpb-binding-decision-tiktok-inquiry-regarding-unfair-design-practices_en
GDPR Articles 25(1) and 25(2) – data protection by design and default,Facebook (Meta Platforms),"The European Data Protection Board reported that the Irish Data Protection Commission fined Meta Platforms €265 million in December 2022 for failing to protect personal data in its Facebook Search, Messenger Contact Importer and Instagram Contact Importer tools.  The inquiry covered the period from May 25, 2018 to September 2019 and concluded that Meta failed to implement appropriate technical and organisational measures to comply with data protection by design and default, as required by GDPR Articles 25(1) and 25(2).  The decision imposed a fine, a reprimand, and an order to bring processing into compliance with GDPRhttps://www.edpb.europa.eu/news/national-news/2022/irish-supervisory-authority-announces-decision-facebook-data-scraping_en#:~:text=,border%2C%20Article%2025.",https://edpb.europa.eu/news/news/2022/edpb-adopts-binding-decision-ordering-irish-dpc-to-adjust-its-approach-facebook-data_en
GDPR – protection of children’s personal data and transparency,Instagram (Meta Platforms),"The EDPB’s September 2022 press release described a decision against Instagram for exposing children’s phone numbers and email addresses and setting personal accounts to “public” by default.  The Irish Data Protection Commission imposed a €405 million fine, the second‑largest GDPR fine at the time, after finding that Instagram’s default settings and publication of children’s contact information violated the GDPR’s requirements for data protection by design and transparency.  The decision required Instagram to change its settings so that children’s accounts are private by default and to ensure that publishing contact details is justified under the GDPRhttps://www.edpb.europa.eu/news/news/2022/record-fine-instagram-following-edpb-intervention_en#:~:text=Brussels%2C%2015%20September%20,GDPR%20fine%20of%20%E2%82%AC405%20million.",https://edpb.europa.eu/news/news/2022/binding-decision-instagram-inquiry-edpb-requires-irish-dpc-reassess-fine-second-largest_en
California Consumer Privacy Act (CCPA) and Children’s Online Privacy Protection Act (COPPA),Tilting Point Media (game: SpongeBob: Krusty Cook‑Off),"The California Attorney General announced in June 2024 a $500,000 settlement with Tilting Point Media for illegally collecting children’s data through the mobile game “SpongeBob: Krusty Cook‑Off.”  The settlement resolved allegations that Tilting Point and its subsidiary Nukebox Studios violated the CCPA and COPPA by collecting and sharing data from children under 13 through third‑party advertising SDKs without adequate notice or consent.  The agreement required the companies to pay a monetary penalty, obtain parental consent before collecting data from children, implement neutral age screens, govern third‑party SDKs, and provide annual reports on compliancehttps://oag.ca.gov/news/press-releases/attorney-general-bonta-la-city-attorney-feldstein-soto-announce-500000#:~:text=Attorney%20General%20Bonta%2C%20L,Collecting%20and%20Sharing%20Children%E2%80%99s%20Data.",https://oag.ca.gov/news/press-releases/attorney-general-bonta-secures-500000-penalty-against-tilting-point-media
California Consumer Privacy Act (CCPA) and California Online Privacy Protection Act (CalOPPA),DoorDash,"In February 2024, the California Attorney General announced a settlement with DoorDash for violating the CCPA and CalOPPA by selling consumers’ personal information through marketing cooperatives without providing notice or a meaningful opportunity to opt out.  The press release explains that DoorDash disclosed customer names, addresses and purchase histories to data cooperatives, which shared the data with other businesses for marketing.  Under the settlement, DoorDash must pay a penalty, provide clear notice and opt‑out options before selling data, conduct regular reviews of vendors’ compliance, and file annual reports with the AG’s officehttps://oag.ca.gov/news/press-releases/attorney-general-bonta-announces-settlement-doordash-investigation-finds-company#:~:text=Attorney%20General%20Bonta%20Announces%20Settlement,Violated%20Multiple%20Consumer%20Privacy%20Laws.",https://oag.ca.gov/news/press-releases/attorney-general-bonta-secures-settlement-against-doordash-violating-privacy-laws
"California Unfair Competition Law, False Advertising Law and COPPA (lawsuit)",TikTok,"A coalition of state attorneys general led by California sued TikTok in October 2024, alleging that the platform’s design and marketing practices harm children and violate state consumer protection statutes and COPPA.  The CA Attorney General’s press release states that TikTok’s algorithm promotes compulsive use through addictive features like endless scroll, autoplay, push notifications, Stories and Likes.  TikTok allegedly misleads users about the safety of its platform, fails to obtain parental consent for users under 13, and deceptively markets the platform as appropriate for young users.  The lawsuit seeks injunctive relief and civil penalties for violations of the Unfair Competition Law, False Advertising Law and COPPAhttps://oag.ca.gov/news/press-releases/attorney-general-bonta-attorney-general-james-lead-coalition-suing-tiktok#:~:text=Attorney%20General%20Bonta%2C%20Attorney%20General,Exploiting%20Young%20Users%2C%20Deceiving%20Public.",https://oag.ca.gov/news/press-releases/attorney-general-bonta-sues-tiktok-exploitation-young-users
Consumer protection laws and COPPA – addictive design harming youth mental health,Meta Platforms (Facebook/Instagram),"In October 2023, a bipartisan coalition of 32 state attorneys general filed a lawsuit against Meta, alleging that the company’s social media platforms, including Facebook and Instagram, harm young users’ mental health.  The New York Attorney General’s press release claims that Meta intentionally designed features such as algorithmic recommendation systems, Likes, infinite scroll and notifications to maximize engagement and time spent, leading to addiction.  The lawsuit also alleges that Meta collected personal data from children under 13 without parental consent, violating COPPA.  The attorneys general seek to stop Meta from deploying harmful design features and to impose civil penalties for violating consumer protection lawshttps://ag.ny.gov/press-release/2023/attorney-general-james-and-multistate-coalition-sue-meta-harming-youth#:~:text=October%2024%2C%202023https://ag.ny.gov/press-release/2023/attorney-general-james-and-multistate-coalition-sue-meta-harming-youth#:~:text=Filing%20lawsuits%20in%20their%20own,and%20the%20District%20of%20Columbia.",https://ag.ny.gov/press-release/2023/oct/nys-ag-james-leads-bipartisan-coalition-attorneys-general-suing-meta-youth-mental-health
"State consumer protection laws, breach notification laws and HIPAA",Blackbaud Inc.,"A multistate investigation led by the Alaska Attorney General resulted in an October 2023 settlement with software company Blackbaud over a 2020 ransomware attack that exposed personal and medical information.  The press release notes that Blackbaud failed to implement reasonable data security and delayed notifying customers and donors of the breach.  These failures violated state consumer protection laws, data breach notification statutes, and the Health Insurance Portability and Accountability Act (HIPAA).  Blackbaud agreed to pay $49.5 million to states and implement enhanced security measures, including encryption, access controls, and a written incident response planfile:///home/oai/redirect.html#:~:text=Attorney%20General%20Taylor%20Announces%20Settlement,Regarding%20Data%20Breachfile:///home/oai/redirect.html#:~:text=Today%E2%80%99s%20settlement%20resolves%20allegations%20of,or%20never%20occurred%20at%20all.",https://law.alaska.gov/news/latest/2023/100523-blackbaud.html
GDPR – valid consent and targeted advertising,Criteo,"In June 2023, France’s data protection authority CNIL imposed a €40 million fine on ad‑tech company Criteo after complaints from privacy group noyb and La Quadrature du Net.  According to noyb’s article, Criteo’s retargeting platform tracks users across the web and displays personalised ads, but CNIL found it could not prove that it had obtained valid consent from users.  The authority concluded that Criteo violated the GDPR by failing to demonstrate a lawful basis for processing.  noyb welcomed the decision and urged enforcement against other ad‑tech firmshttps://noyb.eu/en/advertising-company-criteo-fined-eu40-mio#:~:text=The%20French%20Data%20Protection%20Authority,that%20they%20obtained%20valid%20consent.",https://noyb.eu/en/cnils-decision-criteo-fined-40-million-euros-after-noyb-complaint
GDPR – right of access to personal data,Spotify,"A June 2023 decision by the Swedish Data Protection Authority fined Spotify €5 million after noyb filed a complaint on behalf of a user who was denied full access to their personal data.  According to the noyb article, the authority found that Spotify failed to provide all requested personal data and did not explain how the data was processed, violating Article 15 of the GDPR.  The decision affirms that data controllers must provide complete and intelligible copies of personal data and details of processing.  noyb called the ruling a milestone for users’ rights in Europehttps://noyb.eu/en/spotify-fined-eu-5-million-gdpr-violation#:~:text=Following%20a%20noyb%20complaint%20and,Netherlands%20by%20Bits%20of%20Freedom.",https://noyb.eu/en/spotify-fined-5-million-euro-after-noyb-complaint
GDPR – unlawful data transfers to the U.S.,Meta Platforms (Facebook),"noyb reported in May 2023 that the European Data Protection Board (EDPB) fined Meta €1.2 billion and ordered it to stop transferring personal data of EU users to the United States.  The complaint stemmed from concerns that U.S. surveillance laws (notably FISA 702) did not adequately protect Europeans’ data.  The decision required Meta to suspend data transfers under Standard Contractual Clauses and delete or return affected data.  The article includes comments from privacy activist Max Schrems, who noted that the fine shows that companies cannot simply move data to the U.S. without safeguardshttps://noyb.eu/en/edpb-decision-facebooks-eu-us-data-transfers-stop-transfers-fine-and-repatriation#:~:text=Today%2C%20a%20decade,brought%20back%20to%20the%20EU.",https://noyb.eu/en/eu-us-data-transfers-edpb-fines-meta-record-eu-privacy-case
GDPR – forced consent (bundling) complaints,Google,"On May 25, 2018, the first day of the GDPR, noyb filed complaints against Google and three Facebook-owned services (Facebook, Instagram and WhatsApp) for requiring users to consent to data processing as a condition of using the services.  The article explains that this “forced consent” or bundling violates the GDPR requirement that consent must be freely given.  Users had to agree to extensive data processing (including use of personal data for targeted advertising) or lose access to the services.  noyb argued that such take‑it‑or‑leave‑it consent is invalid and sought fines of up to €7 billionhttps://noyb.eu/en/noybeu-filed-complaints-over-forced-consent-against-google-instagram-whatsapp-and-facebook#:~:text=Privacy%20%C3%A0%20la%20%E2%80%9Ctake%20it,and%20Instagram%20over%20%E2%80%9Cforced%20consent%E2%80%9D.",https://noyb.eu/en/gdpr-complaints-against-google-facebook-instagram-and-whatsapp-forced-consent
GDPR – forced consent (bundling) complaints,Facebook,"noyb’s 2018 forced consent complaints also targeted Facebook.  The article details how Facebook forced users to accept its data processing terms in order to continue using the service on the eve of the GDPR coming into force.  Users were confronted with a “consent screen” and had to agree to the terms to keep their account.  noyb argues that this violates the GDPR’s requirement for freely given consent, as users cannot refuse without consequences.  The complaints sought multi‑billion-euro fineshttps://noyb.eu/en/noybeu-filed-complaints-over-forced-consent-against-google-instagram-whatsapp-and-facebook#:~:text=Privacy%20%C3%A0%20la%20%E2%80%9Ctake%20it,and%20Instagram%20over%20%E2%80%9Cforced%20consent%E2%80%9D.",https://noyb.eu/en/gdpr-complaints-against-google-facebook-instagram-and-whatsapp-forced-consent
GDPR – forced consent (bundling) complaints,Instagram,"The 2018 noyb article describes complaints against Instagram for forcing users to consent to extensive data processing to use the platform.  To access Instagram after May 25, 2018, users had to accept a new data policy that allowed Instagram to share data with parent company Facebook and third parties for targeted advertising.  noyb alleges that this forced consent violates the GDPR because consent must be freely given and cannot be bundled with service usehttps://noyb.eu/en/noybeu-filed-complaints-over-forced-consent-against-google-instagram-whatsapp-and-facebook#:~:text=Privacy%20%C3%A0%20la%20%E2%80%9Ctake%20it,and%20Instagram%20over%20%E2%80%9Cforced%20consent%E2%80%9D.",https://noyb.eu/en/gdpr-complaints-against-google-facebook-instagram-and-whatsapp-forced-consent
GDPR – forced consent (bundling) complaints,WhatsApp,"The same 2018 complaints note that WhatsApp required users to accept a new privacy policy that allowed extensive data sharing with Facebook in order to continue using the messaging app.  noyb argued that by conditioning service on acceptance of the policy, WhatsApp violated the GDPR’s requirement that consent be freely given.  The complaints requested that data protection authorities impose significant fines and require unbundled consent formshttps://noyb.eu/en/noybeu-filed-complaints-over-forced-consent-against-google-instagram-whatsapp-and-facebook#:~:text=Privacy%20%C3%A0%20la%20%E2%80%9Ctake%20it,and%20Instagram%20over%20%E2%80%9Cforced%20consent%E2%80%9D.",https://noyb.eu/en/gdpr-complaints-against-google-facebook-instagram-and-whatsapp-forced-consent
GDPR – illegal sharing of personal data for advertising,Grindr,"In January 2020, the Norwegian Consumer Council and noyb filed complaints with the Norwegian Data Protection Authority against Grindr and several ad‑tech companies.  The report revealed that Grindr shared users’ personal data – including GPS location, age, gender and sexual orientation – with third‑party advertising companies without valid consent.  The complaint argued that such sharing violates the GDPR’s requirements for lawful processing and legitimate interest.  The Norwegian authority later imposed a substantial fine on Grindr.  The noyb article emphasises that data from LGBTQ+ dating app users is highly sensitivehttps://noyb.eu/en/three-gdpr-complaints-filed-against-grindr-twitter-and-adtech-companies-smaato-openx-adcolony-and#:~:text=,targeted%20advertising%20and%20other%20purposes.",https://noyb.eu/en/dating-app-grindr-shares-users-personal-data-adtech-companies
GDPR – illegal sharing of personal data for advertising,Twitter’s MoPub (ad platform),"The January 2020 complaints also targeted MoPub, Twitter’s mobile advertising subsidiary, for receiving and distributing personal data from Grindr without valid consent.  According to the noyb article, MoPub acted as a central hub connecting Grindr’s data to multiple ad‑tech partners, enabling the sale of sensitive personal information.  The complaint alleges that MoPub failed to ensure a legal basis and that such sharing violated the GDPR.  The Norwegian authority later signaled it would investigate these practiceshttps://noyb.eu/en/three-gdpr-complaints-filed-against-grindr-twitter-and-adtech-companies-smaato-openx-adcolony-and#:~:text=,targeted%20advertising%20and%20other%20purposes.",https://noyb.eu/en/dating-app-grindr-shares-users-personal-data-adtech-companies
GDPR – illegal sharing of personal data for advertising,Smaato,"Smaato, another ad‑tech company named in the 2020 complaints, received personal data from Grindr via MoPub and used it for targeted advertising.  The noyb article explains that Smaato integrated numerous data sources and acted as a data broker, yet did not obtain consent from Grindr users.  The complaint argued this violated the GDPR, as sensitive data (including sexual orientation) cannot be processed without explicit consent.  The Norwegian Consumer Council and noyb urged regulators to investigate and sanction the companyhttps://noyb.eu/en/three-gdpr-complaints-filed-against-grindr-twitter-and-adtech-companies-smaato-openx-adcolony-and#:~:text=,targeted%20advertising%20and%20other%20purposes.",https://noyb.eu/en/dating-app-grindr-shares-users-personal-data-adtech-companies
GDPR – illegal sharing of personal data for advertising,AdColony,"AdColony, an ad‑tech company, was also named in the 2020 complaints for receiving users’ personal data from Grindr.  The noyb article describes how Grindr and MoPub shared sensitive information such as user location and sexual orientation with AdColony for targeted advertising, without obtaining valid consent.  The complaint alleged that AdColony failed to ensure a lawful basis and thereby violated the GDPR.  The case highlighted the systemic problems in the real‑time bidding ecosystemhttps://noyb.eu/en/three-gdpr-complaints-filed-against-grindr-twitter-and-adtech-companies-smaato-openx-adcolony-and#:~:text=,targeted%20advertising%20and%20other%20purposes.",https://noyb.eu/en/dating-app-grindr-shares-users-personal-data-adtech-companies
GDPR – illegal sharing of personal data for advertising,OpenX,"OpenX, another ad‑tech company listed in the 2020 complaints, received personal data from Grindr through MoPub.  According to the noyb article, OpenX processed location, IP addresses and device identifiers for targeted advertising without users’ consent.  This practice allegedly violated the GDPR’s requirements for a lawful basis and transparency.  The complaints urged regulators to impose significant fines on OpenX and similar ad‑tech intermediarieshttps://noyb.eu/en/three-gdpr-complaints-filed-against-grindr-twitter-and-adtech-companies-smaato-openx-adcolony-and#:~:text=,targeted%20advertising%20and%20other%20purposes.",https://noyb.eu/en/dating-app-grindr-shares-users-personal-data-adtech-companies
GDPR – right of access to personal data and failure to respond to requests,TikTok,"In July 2025, noyb filed complaints against TikTok, AliExpress and WeChat after the companies failed to respond properly to Article 15 GDPR requests.  The article notes that noyb staff and volunteers requested their personal data from these companies but received incomplete responses or no responses at all.  The complaints allege that the companies violated the GDPR by ignoring data subject access rights and by failing to provide information about data processing.  noyb asked data protection authorities to impose fines of up to 4% of global turnoverhttps://noyb.eu/en/how-tiktok-aliexpress-wechat-ignore-your-gdpr-rights#:~:text=%2F%C2%A0%2017%20July%202025.",https://noyb.eu/en/tiktok-aliexpress-wechat-ignore-gdpr-rights-noyb-complaints
GDPR – right of access to personal data and failure to respond to requests,AliExpress,"The same July 2025 noyb complaints targeted AliExpress for failing to respond to data access requests.  The article states that AliExpress did not provide the requested personal data and information about processing, violating Article 15 GDPR.  noyb contends that as a large online marketplace, AliExpress must comply with EU data protection law and respect users’ rights.  It calls on regulators to fine the company and ensure compliancehttps://noyb.eu/en/how-tiktok-aliexpress-wechat-ignore-your-gdpr-rights#:~:text=%2F%C2%A0%2017%20July%202025.",https://noyb.eu/en/tiktok-aliexpress-wechat-ignore-gdpr-rights-noyb-complaints
GDPR – right of access to personal data and failure to respond to requests,WeChat (Tencent),"The July 2025 noyb complaints also included WeChat, which, according to the article, refused to provide any personal data in response to GDPR access requests.  noyb argues that WeChat is obligated to comply with EU data protection law because it offers services to EU residents.  By ignoring access requests, WeChat violated Article 15 and may face fines and corrective ordershttps://noyb.eu/en/how-tiktok-aliexpress-wechat-ignore-your-gdpr-rights#:~:text=%2F%C2%A0%2017%20July%202025.",https://noyb.eu/en/tiktok-aliexpress-wechat-ignore-gdpr-rights-noyb-complaints
GDPR – unlawful transfer of personal data to China,TikTok,"In January 2025, noyb filed complaints against TikTok and other China‑based companies for unlawfully transferring European users’ data to China.  The article explains that EU law prohibits personal data from being sent to countries without adequate safeguards.  noyb argues that Chinese companies must demonstrate that EU citizens’ data is protected against government surveillance.  It alleges that TikTok continues to transfer user data to China despite promises to localize data in Europe, violating the GDPR’s transfer restrictionshttps://noyb.eu/en/tiktok-aliexpress-shein-co-surrender-europeans-data-authoritarian-china#:~:text=%2F%C2%A0%2016%20January%202025.",https://noyb.eu/en/chinese-apps-transfer-european-data-to-china-noyb-complaints
GDPR – unlawful transfer of personal data to China,AliExpress,"The same January 2025 complaints accuse AliExpress of sending European users’ data to China without adequate safeguards.  According to the article, AliExpress collects personal and transaction data from European customers and transfers it to servers in China, where Chinese security agencies may access it.  noyb contends that such transfers violate the GDPR’s requirement for appropriate safeguards and calls for heavy fines to deter further violationshttps://noyb.eu/en/tiktok-aliexpress-shein-co-surrender-europeans-data-authoritarian-china#:~:text=%2F%C2%A0%2016%20January%202025.",https://noyb.eu/en/chinese-apps-transfer-european-data-to-china-noyb-complaints
GDPR – unlawful transfer of personal data to China,Shein,"noyb’s January 2025 complaints also target fast‑fashion retailer Shein for transferring European customers’ personal data to China.  The article states that Shein collects personal information through its app and website and stores it in China, where the data may be accessed by Chinese authorities.  noyb alleges this violates the GDPR’s restrictions on data transfers to third countries and demands that data protection authorities order Shein to stop the transfers and impose significant fineshttps://noyb.eu/en/tiktok-aliexpress-shein-co-surrender-europeans-data-authoritarian-china#:~:text=%2F%C2%A0%2016%20January%202025.",https://noyb.eu/en/chinese-apps-transfer-european-data-to-china-noyb-complaints
GDPR – tracking without consent,Pinterest,"In October 2024, noyb filed a complaint against Pinterest for placing tracking cookies and processing personal data for personalised ads without valid consent.  The article explains that Pinterest relies on a “legitimate interest” argument to avoid asking for consent but still uses cookies and tracking technologies to build user profiles.  noyb argues that this practice violates the GDPR because personalised advertising requires opt‑in consent.  The complaint requests that authorities fine Pinterest and require it to collect valid consenthttps://noyb.eu/en/pinterest-pins-users-data-down-without-consent#:~:text=Today%2C%20noyb%C2%A0filed%20a%20complaint%20against,legally%20flawed%20argument%20years%20ago.",https://noyb.eu/en/pinterest-spies-users-data-after-cookie-consent-rejection
GDPR – unnecessary data collection for offline games,Ubisoft,"noyb’s April 2025 complaint accuses game developer Ubisoft of forcing players of its offline games to connect to the internet so it can collect data about their gameplay.  According to the article, Ubisoft collects information about when players start a game, how long they play and which servers they connect to, even for single‑player games.  noyb argues there is no legal basis for this data collection under the GDPR because the information is not necessary for providing the game.  It asks the Austrian Data Protection Authority to declare the processing unlawful and to impose a finehttps://noyb.eu/en/play-alone-ubisoft-still-watching-you#:~:text=Today%2C%20noyb%20filed%20a%20complaint,randomly%20collect%20such%20user%20data.",https://noyb.eu/en/ubisoft-forces-offline-gamers-connect-internet-gdpr-complaint
GDPR – unlawful use of personal data for AI training and failure to offer opt‑out,Meta Platforms (Facebook/Instagram),"In June 2024, noyb lodged complaints with 11 European data protection authorities to stop Meta from using all user data for training its artificial intelligence systems.  The article explains that Meta planned to change its privacy policy to claim a “legitimate interest” for AI training and would use posts, interactions and tracking data for unspecified AI technologies.  noyb argues this violates the GDPR because Meta failed to obtain consent and offered an impractical opt‑out that required scanning ID documents and describing personal reasons.  The complaints ask authorities to prohibit the practice and fine Metahttps://noyb.eu/en/noyb-urges-11-dpas-immediately-stop-metas-abuse-personal-data-ai#:~:text=Over%20the%20past%20few%20days%2C,force%20on%2026%20June%202024.",https://noyb.eu/en/meta-ai-draft-gdpr-complaints
GDPR – inaccurate personal data and failure to rectify,OpenAI (ChatGPT),"noyb’s April 2024 complaint against OpenAI argues that the company’s ChatGPT system cannot correct false information about individuals, violating the GDPR’s accuracy and rectification requirements.  The article notes that ChatGPT invents details about people and cannot provide sources for its statements.  When an individual demanded correction of false claims, OpenAI responded that it could not fix the data due to the way the system works.  noyb contends that providing inaccurate personal data and refusing to rectify it violates Articles 5(1)(d) and 16 of the GDPR and asks regulators to order OpenAI to comply and impose a finehttps://noyb.eu/en/chatgpt-provides-false-information-about-people-and-openai-cant-correct-it#:~:text=In%20the%20EU%2C%20the%20GDPR,OpenAI%20with%20the%20Austrian%20DPA.",https://noyb.eu/en/chatgpt-cant-fix-false-information-noyb-files-gdpr-complaint
GDPR – unlawful use of personal data for AI training and lack of consent,Twitter (X) – AI training,"In August 2024, noyb filed nine complaints against Twitter (now X) after the company began using the personal data of about 60 million EU users to train its AI systems, including the “Grok” chatbot.  The article explains that Twitter claimed a legitimate interest for the processing but did not obtain user consent or provide clear opt‑outs.  noyb argues that the processing of social media posts, messages and interactions for AI training lacks a lawful basis under the GDPR.  It asks regulators in Austria, Spain, Italy and other countries to order Twitter to stop processing and impose fineshttps://noyb.eu/en/twitters-ai-plans-hit-9-more-gdpr-complaints#:~:text=Recently%2C%20Twitter%20International%20%28now%20re,follows%20up%20with%20nine%20complaints.",https://noyb.eu/en/twitter-recycles-personal-data-train-its-ai-new-wave-gdpr-complaints
GDPR and Digital Services Act – illegal micro‑targeting of political ads,Twitter (X),"In December 2023, noyb filed a complaint against Twitter/X for illegally using sensitive personal data to micro‑target European users with political advertising.  The article states that Twitter promoted the EU’s “chat control” regulation to users based on inferred political views, religious beliefs and sexual orientation, in violation of the GDPR and the Digital Services Act.  X’s advertising rules prohibit targeting based on sensitive categories, but the platform ignored its own policies.  noyb asked the Dutch Data Protection Authority to impose a fine and require X to cease the micro‑targetinghttps://noyb.eu/en/gdpr-complaint-against-x-twitter-over-illegal-micro-targeting-chat-control-ads#:~:text=Today%2C%20noyb%20filed%20a%20complaint,the%20GDPR%20and%20the%20DSA.",https://noyb.eu/en/x-illegally-micro-targeted-eu-users-sensitive-data-noyb-files-complaint
GDPR – dark pattern consent banners and repeated prompts,BeReal,"In December 2024, noyb filed a complaint against the social media platform BeReal for using a consent banner that repeatedly pressures users to accept tracking cookies.  According to the article, when users refuse consent, the banner reappears every 24 hours, creating a dark pattern designed to coerce users into agreeing.  noyb argues that such repeated requests invalidate consent under the GDPR because consent must be freely given and unambiguous.  The complaint asks the French data protection authority CNIL to declare the practice unlawful and impose a finehttps://noyb.eu/en/bereal-app-wont-take-no-answer#:~:text=Today%2C%20noyb%20has%20filed%20a,latest%20trend%20in%20%E2%80%9Cdark%20pattern%E2%80%9D.",https://noyb.eu/en/bereal-dark-pattern-cookie-consent
Consumer protection law and GDPR – AI training without consent,Meta Platforms (Verbraucherzentrale NRW case),"In May 2025, German consumer organisation Verbraucherzentrale NRW and noyb sent Meta a cease and desist letter after the company announced it would use all personal data – posts, photos and other content – for training its AI systems.  The article explains that Meta planned to rely on a “legitimate interest” justification and did not provide a proper opt‑in mechanism.  Verbraucherzentrale NRW argues that Meta’s plan violates the GDPR, particularly because users are not offered a real choice.  The letter threatened legal action if Meta did not withdraw its AI training policyhttps://noyb.eu/en/verbraucherzentrale-nrw-requests-meta-cease-and-desist-ai-training-eu#:~:text=On%2014%20April%2C%20Meta%20announced,fully%20supports%20the%20Verbraucherzentrale%27s%20action.",https://noyb.eu/en/meta-ai-training-sued-german-consumer-organisation
GDPR – scraping LinkedIn data without consent,KASPR (Leads / Captain Data),"The EDPB’s national news section reported that the French data protection authority CNIL fined KASPR (also known as Captain Data) €240,000 for scraping personal data from LinkedIn without a legal basis.  KASPR offered a browser extension that allowed users to collect the contact details of LinkedIn profiles and use them for marketing.  CNIL found multiple GDPR breaches: no lawful basis for processing, indefinite retention periods, failure to inform individuals about the data collection, and refusal to honor data deletion requests.  It ordered the company to cease scraping and to comply with transparency and retention requirementshttps://www.edpb.europa.eu/news/news/2025/data-scraping-french-supervisory-authority-fined-kaspr-eu240-000_en#:~:text=.",https://edpb.europa.eu/news/national-news/2024/cnil-imposes-eu240000-fine-kaspr-leads-unlawful-scraping-linkedin-profiles_en
COPPA and FTC Act – collection of children’s data without consent,Epic Games (Fortnite),"The U.S. Department of Justice announced in December 2022 that Epic Games agreed to pay a $275 million civil penalty for violating the Children’s Online Privacy Protection Act by collecting personal information from children under 13 who played Fortnite without notifying parents or obtaining consent.  The complaint alleged Epic’s default settings enabled real‑time voice and text communications between children and adults, exposing children to bullying and harassment.  The settlement requires Epic to implement privacy safeguards, disable live communications by default for minors, delete personal data previously collected in violation of COPPA, and submit periodic audits to the FTChttps://www.justice.gov/archives/opa/pr/epic-games-inc-developer-fortnite-video-game-agrees-275-million-penalty-and-injunction#:~:text=Office%20of%20Public%20Affairs.",https://www.justice.gov/opa/pr/epic-games-agrees-pay-520-million-settle-ftc-allegations-dark-patterns-privacy-violations
Digital Markets Act – anti‑steering and unfair consent or pay model,Apple,"An April 2025 European Commission press release announced that Apple and Meta were found in breach of the Digital Markets Act (DMA).  The Commission concluded that Apple violated the DMA’s anti‑steering obligation by preventing app developers from informing users about alternative, cheaper offers outside the App Store.  Apple also charged high fees for external payments.  The Commission ordered Apple to remove anti‑steering clauses and remove technical restrictions, imposing a fine of €500 million for non‑compliance.  The press release notes that the DMA requires gatekeepers like Apple to allow developers to steer users to third‑party offers and to refrain from self‑preferencing.  The decision opens a formal investigation into Apple’s compliance.",https://ec.europa.eu/commission/presscorner/detail/en/ip_25_2076
Digital Markets Act – unfair consent-or-pay and anti‑steering,Meta Platforms (Facebook/Instagram),The same April 2025 Commission press release stated that Meta breached the Digital Markets Act by offering a “consent or pay” model that forced EU users to either accept personalised advertising or pay a subscription.  The Commission found that Meta’s model failed to provide a genuinely equivalent alternative service and thus did not comply with the DMA’s requirement to allow users to opt for less personal data use.  Meta was fined €200 million.  The Commission also noted that Meta had previously been fined €1.2 billion under the GDPR for data transfers.  The DMA decision requires Meta to provide a version of its social networks that uses less personal data without charging users.,https://ec.europa.eu/commission/presscorner/detail/en/ip_25_2076
Antitrust – abuse of dominant position (Article 102 TFEU),Meta Platforms (Facebook),"In November 2024, the European Commission fined Meta €797.72 million for tying Facebook Marketplace to the social network and imposing unfair trading conditions on competing classified advertising services.  According to the Commission’s press release, Meta embedded the Marketplace as a feature of Facebook, automatically giving it access to the social network’s user base and data.  This practice constituted an abusive tying and self‑preferencing under Article 102 of the Treaty on the Functioning of the European Union (TFEU).  Meta also imposed unfair trading conditions on competitors that use Facebook for business, which hindered competition.  The Commission ordered Meta to stop the conduct and align its practices with EU antitrust rules.",https://ec.europa.eu/commission/presscorner/detail/en/ip_24_6136
FTC Act – unfair and deceptive practices (invasion of privacy),Amazon/Ring,"A June 2023 Electronic Frontier Foundation article summarised the FTC’s settlement with Ring, a home‑security camera company owned by Amazon.  The FTC alleged that Ring gave employees and contractors unrestricted access to customers’ private video footage and failed to implement basic security protections, allowing hackers to access accounts.  The settlement required Ring to pay $5.8 million in refunds, delete any products or algorithms derived from improperly obtained data, implement a comprehensive privacy and security program, and require multi‑factor authentication for all customer accounts.  The EFF article criticised the settlement for not addressing Ring’s business model of pervasive surveillance and called for stronger privacy protectionshttps://www.eff.org/deeplinks/2023/06/ftc-forces-ring-take-user-privacy-seriously#:~:text=,device%20on%20a%20closed%20door.",https://www.eff.org/deeplinks/2023/06/ftc-settlement-ring-doesnt-do-enough-protect-users-privacy
